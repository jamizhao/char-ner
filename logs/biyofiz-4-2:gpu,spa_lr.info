activation:	bi-lstm
batch_norm:	0
breaktrn:	0
captrn:	0
curriculum:	1
decoder:	0
drates:	[0, 0, 0]
emb:	0
eps:	1e-08
fbias:	0.2
fbmerge:	sum
feat:	basic
fepoch:	5000
gclip:	0
gnoise:	False
in2out:	0
lang:	spa
log:	spa_lr
lr:	0.002
n_batch:	32
n_hidden:	[128, 128]
norm:	1.0
opt:	adam
patience:	-1
recout:	0
rep:	std
reverse:	False
rnn:	lazrnn
sample:	0
save:	False
shuf:	1
sorted:	1
tagging:	io
truncate:	-1
base_log_name:	biyofiz-4-2:gpu,spa_lr
# of sents trn, dev, tst: 8322 1915 1517
maxlen: 1916 minlen: 1 avglen: 169.88 stdlen: 118.66
[u'c= ', u'c=!', u'c="', u'c=%', u'c=&', u"c='", u'c=(', u'c=)', u'c=+', u'c=,', u'c=-', u'c=.', u'c=/', u'c=0', u'c=1', u'c=2', u'c=3', u'c=4', u'c=5', u'c=6', u'c=7', u'c=8', u'c=9', u'c=:', u'c=;', u'c==', u'c=?', u'c=@', u'c=A', u'c=B', u'c=C', u'c=D', u'c=E', u'c=F', u'c=G', u'c=H', u'c=I', u'c=J', u'c=K', u'c=L', u'c=M', u'c=N', u'c=O', u'c=P', u'c=Q', u'c=R', u'c=S', u'c=T', u'c=U', u'c=V', u'c=W', u'c=X', u'c=Y', u'c=Z', u'c=a', u'c=b', u'c=c', u'c=d', u'c=e', u'c=f', u'c=g', u'c=h', u'c=i', u'c=j', u'c=k', u'c=l', u'c=m', u'c=n', u'c=o', u'c=p', u'c=q', u'c=r', u'c=s', u'c=t', u'c=u', u'c=v', u'c=w', u'c=x', u'c=y', u'c=z', u'c=\xa1', u'c=\xb7', u'c=\xbf', u'c=\xd1', u'c=\xe0', u'c=\xe1', u'c=\xe9', u'c=\xed', u'c=\xf1', u'c=\xf3', u'c=\xfa', u'c=\xfc']
['i-loc' 'i-misc' 'i-org' 'i-per' 'o']
['I-LOC' 'I-MISC' 'I-ORG' 'I-PER' 'O']
NF: 92 NC: 5
Compiling functions...
Compiling done.
training the model...
dset  epoch      mcost      mtime       cerr       werr       wacc        pre     recall         f1       best       best 
