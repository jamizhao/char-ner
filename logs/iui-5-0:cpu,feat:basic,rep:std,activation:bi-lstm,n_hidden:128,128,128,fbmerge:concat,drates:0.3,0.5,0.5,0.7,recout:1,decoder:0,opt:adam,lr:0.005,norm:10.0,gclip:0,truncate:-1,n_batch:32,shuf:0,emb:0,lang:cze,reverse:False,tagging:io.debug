activation:	bi-lstm
batch_norm:	128
curriculum:	1
decoder:	0
drates:	[0.3, 0.5, 0.5, 0.7]
emb:	0
fbmerge:	concat
feat:	basic
fepoch:	5000
gclip:	0
in2out:	0
lang:	cze
log:	das_auto
lr:	0.005
n_batch:	32
n_hidden:	[128, 128, 128]
norm:	10.0
opt:	adam
patience:	5
recout:	1
rep:	std
reverse:	False
rnn:	lazrnn
sample:	0
save:	False
shuf:	0
sorted:	1
tagging:	io
truncate:	-1
base_log_name:	iui-5-0:cpu,feat:basic,rep:std,activation:bi-lstm,n_hidden:128,128,128,fbmerge:concat,drates:0.3,0.5,0.5,0.7,recout:1,decoder:0,opt:adam,lr:0.005,norm:10.0,gclip:0,truncate:-1,n_batch:32,shuf:0,emb:0,lang:cze,reverse:False,tagging:io
# of sents trn, dev, tst: 4644 572 577
maxlen: 691 minlen: 3 avglen: 156.05 stdlen: 99.52
['c= ', 'c=!', 'c="', 'c=$', 'c=%', 'c=&', "c='", 'c=(', 'c=)', 'c=*', 'c=+', 'c=,', 'c=-', 'c=.', 'c=/', 'c=0', 'c=1', 'c=2', 'c=3', 'c=4', 'c=5', 'c=6', 'c=7', 'c=8', 'c=9', 'c=:', 'c=;', 'c=<', 'c==', 'c=>', 'c=?', 'c=@', 'c=A', 'c=B', 'c=C', 'c=D', 'c=E', 'c=F', 'c=G', 'c=H', 'c=I', 'c=J', 'c=K', 'c=L', 'c=M', 'c=N', 'c=O', 'c=P', 'c=Q', 'c=R', 'c=S', 'c=T', 'c=U', 'c=V', 'c=W', 'c=X', 'c=Y', 'c=Z', 'c=[', 'c=\\', 'c=]', 'c=_', 'c=`', 'c=a', 'c=b', 'c=c', 'c=d', 'c=e', 'c=f', 'c=g', 'c=h', 'c=i', 'c=j', 'c=k', 'c=l', 'c=m', 'c=n', 'c=o', 'c=p', 'c=q', 'c=r', 'c=s', 'c=t', 'c=u', 'c=v', 'c=w', 'c=x', 'c=y', 'c=z', 'c=\x81', 'c=\x84', 'c=\x87', 'c=\x88', 'c=\x89', 'c=\x8c', 'c=\x8d', 'c=\x8e', 'c=\x8f', 'c=\x90', 'c=\x98', 'c=\x99', 'c=\x9a', 'c=\x9b', 'c=\x9c', 'c=\x9d', 'c=\xa0', 'c=\xa1', 'c=\xa2', 'c=\xa4', 'c=\xa5', 'c=\xa7', 'c=\xa9', 'c=\xad', 'c=\xae', 'c=\xaf', 'c=\xb0', 'c=\xb1', 'c=\xb3', 'c=\xb5', 'c=\xb6', 'c=\xb9', 'c=\xba', 'c=\xbc', 'c=\xbd', 'c=\xbe', 'c=\xc2', 'c=\xc3', 'c=\xc4', 'c=\xc5']
['i-a' 'i-g' 'i-i' 'i-m' 'i-o' 'i-p' 'i-t' 'o']
['I-A' 'I-G' 'I-I' 'I-M' 'I-O' 'I-P' 'I-T' 'O']
NF: 129 NC: 8
l_in: (None, None, 129)
l_mask: (Subtensor{int64}.0, Subtensor{int64}.0)
l_drop: (None, None, 129)
l_forward: (None, None, 128)
l_backward: (None, None, 128)
l_fbmerge: (None, None, 256)
using batch norm
l_forward: (None, None, 128)
l_backward: (None, None, 128)
l_fbmerge: (None, None, 256)
using batch norm
l_forward: (None, None, 128)
l_backward: (None, None, 128)
l_fbmerge: (None, None, 256)
using batch norm
using recout:1.
l_out: (None, None, 8)
[W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, beta, gamma, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, beta, gamma, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, beta, gamma, W, b, W]
Compiling functions...
Compiling done.
training the model...
dset  epoch      mcost      mtime       cerr       werr       wacc        pre     recall         f1       best       best 
trn   1        42.4285   698.4298     0.5638     0.5562    44.3800     0.9100     0.8100     0.8600     0.8600          1

processed 119681 tokens with 14163 phrases; found: 12653 phrases; correct: 115.
accuracy:  44.38%; precision:   0.91%; recall:   0.81%; FB1:   0.86
                A: precision:   0.00%; recall:   0.00%; FB1:   0.00  230
                G: precision:   0.64%; recall:   0.14%; FB1:   0.23  628
                I: precision:   1.01%; recall:   1.27%; FB1:   1.13  3153
                M: precision:   0.06%; recall:   0.82%; FB1:   0.11  3541
                O: precision:   0.30%; recall:   0.45%; FB1:   0.36  3724
                P: precision:   4.62%; recall:   0.57%; FB1:   1.02  455
                T: precision:   4.88%; recall:   1.92%; FB1:   2.75  922

bos	i-a	i-g	i-i	i-m	i-o	i-p	i-t	o
i-a	10	0	0	115	91	0	56	282
i-g	605	395	2055	4729	5254	301	378	12827
i-i	1040	218	2624	5892	6611	210	492	18789
i-m	134	35	175	278	353	21	17	1365
i-o	4358	146	1178	3587	3159	128	349	18930
i-p	961	397	4001	7306	8384	680	477	22177
i-t	1410	149	388	1486	1601	59	1373	7856
o	17479	6762	35375	80840	106773	3716	9672	307094

bos	I-A	I-G	I-I	I-M	I-O	I-P	I-T	O
I-A	5	0	0	31	23	0	13	89
I-G	83	63	303	669	712	43	60	1798
I-I	161	33	414	915	950	30	74	2758
I-M	25	6	33	61	60	4	7	234
I-O	698	22	208	714	606	23	99	3336
I-P	140	54	591	1032	1177	109	80	3190
I-T	325	41	99	399	408	17	408	1990
O	3041	1132	5595	14016	16497	630	1903	51444


dev   1        10.9761    21.3209     0.5562     0.5508    44.9200     0.7800     0.6500     0.7100     0.7100          1

processed 14796 tokens with 1860 phrases; found: 1533 phrases; correct: 12.
accuracy:  44.92%; precision:   0.78%; recall:   0.65%; FB1:   0.71
                A: precision:   0.00%; recall:   0.00%; FB1:   0.00  32
                G: precision:   1.08%; recall:   0.25%; FB1:   0.41  93
                I: precision:   0.54%; recall:   0.62%; FB1:   0.58  373
                M: precision:   0.00%; recall:   0.00%; FB1:   0.00  415
                O: precision:   0.00%; recall:   0.00%; FB1:   0.00  438
                P: precision:   4.23%; recall:   0.61%; FB1:   1.07  71
                T: precision:   5.41%; recall:   2.19%; FB1:   3.12  111

bos	i-a	i-g	i-i	i-m	i-o	i-p	i-t	o
i-a	1	0	0	45	1	0	15	129
i-g	58	51	293	675	578	41	73	1904
i-i	97	22	243	774	687	31	63	2093
i-m	0	6	4	38	22	0	0	254
i-o	727	31	119	442	347	31	107	2284
i-p	85	100	380	1003	1214	132	23	2877
i-t	200	8	40	111	230	14	164	943
o	1641	922	4691	10039	12153	470	954	38690

bos	I-A	I-G	I-I	I-M	I-O	I-P	I-T	O
I-A	0	0	0	14	0	0	5	37
I-G	8	8	41	98	78	5	11	250
I-I	11	4	40	119	96	7	7	322
I-M	0	1	2	7	3	0	0	40
I-O	130	3	22	90	68	5	18	422
I-P	13	20	61	146	163	20	4	411
I-T	42	2	8	30	57	4	49	231
O	270	157	724	1764	1920	80	194	6454


tst   1        22.2226    24.4075     0.5682     0.5633    43.6700     0.5000     0.4200     0.4600     0.4600          1

processed 15061 tokens with 1894 phrases; found: 1588 phrases; correct: 8.
accuracy:  43.67%; precision:   0.50%; recall:   0.42%; FB1:   0.46
                A: precision:   0.00%; recall:   0.00%; FB1:   0.00  30
                G: precision:   2.74%; recall:   0.59%; FB1:   0.97  73
                I: precision:   0.26%; recall:   0.33%; FB1:   0.29  382
                M: precision:   0.00%; recall:   0.00%; FB1:   0.00  451
                O: precision:   0.00%; recall:   0.00%; FB1:   0.00  453
                P: precision:   3.57%; recall:   0.64%; FB1:   1.08  84
                T: precision:   1.74%; recall:   0.56%; FB1:   0.84  115

bos	i-a	i-g	i-i	i-m	i-o	i-p	i-t	o
i-a	0	0	0	32	5	0	16	26
i-g	14	72	199	626	557	37	7	1626
i-i	282	38	354	486	768	25	70	2588
i-m	8	0	9	20	16	5	0	192
i-o	810	6	160	596	525	8	69	2960
i-p	55	61	562	1275	1023	135	39	2851
i-t	183	29	26	257	166	15	152	1216
o	1764	797	4151	10487	12747	653	1140	38056

bos	I-A	I-G	I-I	I-M	I-O	I-P	I-T	O
I-A	0	0	0	9	2	0	6	11
I-G	3	14	27	91	70	6	2	238
I-I	40	5	54	71	105	4	11	379
I-M	4	0	3	3	3	1	0	34
I-O	129	1	30	101	91	2	20	522
I-P	8	8	81	189	140	19	8	404
I-T	39	4	7	66	41	5	40	310
O	326	127	668	1840	1951	104	228	6356



dset  epoch      mcost      mtime       cerr       werr       wacc        pre     recall         f1       best       best 
