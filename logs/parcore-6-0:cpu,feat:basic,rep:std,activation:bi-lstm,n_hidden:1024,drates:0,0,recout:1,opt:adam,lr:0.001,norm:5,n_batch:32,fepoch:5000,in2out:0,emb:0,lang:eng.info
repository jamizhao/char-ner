activation:	['bi-lstm']
batch_norm:	0
curriculum:	1
drates:	[0, 0]
emb:	0
feat:	basic
fepoch:	5000
grad_clip:	-1
in2out:	0
lang:	eng
log:	das_auto
lr:	0.001
n_batch:	32
n_hidden:	[1024]
norm:	5
opt:	adam
patience:	-1
recout:	1
rep:	std
rnn:	lazrnn
sample:	0
sorted:	1
truncate:	-1
base_log_name:	parcore-6-0:cpu,feat:basic,rep:std,activation:bi-lstm,n_hidden:1024,drates:0,0,recout:1,opt:adam,lr:0.001,norm:5,n_batch:32,fepoch:5000,in2out:0,emb:0,lang:eng
# of sents trn, dev, tst: 14041 3250 3453
maxlen: 512 minlen: 1 avglen: 76.89 stdlen: 65.57
['c= ', 'c=!', 'c="', 'c=$', 'c=%', 'c=&', "c='", 'c=(', 'c=)', 'c=*', 'c=+', 'c=,', 'c=-', 'c=.', 'c=/', 'c=0', 'c=1', 'c=2', 'c=3', 'c=4', 'c=5', 'c=6', 'c=7', 'c=8', 'c=9', 'c=:', 'c=;', 'c==', 'c=?', 'c=@', 'c=A', 'c=B', 'c=C', 'c=D', 'c=E', 'c=F', 'c=G', 'c=H', 'c=I', 'c=J', 'c=K', 'c=L', 'c=M', 'c=N', 'c=O', 'c=P', 'c=Q', 'c=R', 'c=S', 'c=T', 'c=U', 'c=V', 'c=W', 'c=X', 'c=Y', 'c=Z', 'c=[', 'c=]', 'c=`', 'c=a', 'c=b', 'c=c', 'c=d', 'c=e', 'c=f', 'c=g', 'c=h', 'c=i', 'c=j', 'c=k', 'c=l', 'c=m', 'c=n', 'c=o', 'c=p', 'c=q', 'c=r', 'c=s', 'c=t', 'c=u', 'c=v', 'c=w', 'c=x', 'c=y', 'c=z']
['loc' 'misc' 'o' 'org' 'per']
['B-LOC' 'B-MISC' 'B-ORG' 'I-LOC' 'I-MISC' 'I-ORG' 'I-PER' 'O']
NF: 85 NC: 5
using recout.
Compiling functions...
Compiling done.
training the model...
dset  epoch      mcost      mtime       cerr       werr       wacc        pre     recall         f1       best       best 
